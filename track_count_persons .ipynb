{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4961e54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea686499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics==8.0.106\n",
      "  Downloading ultralytics-8.0.106-py3-none-any.whl (587 kB)\n",
      "     ------------------------------------- 587.4/587.4 kB 30.3 kB/s eta 0:00:00\n",
      "Collecting torchvision>=0.8.1\n",
      "  Using cached torchvision-0.20.1-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Collecting opencv-python>=4.6.0\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Requirement already satisfied: psutil in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from ultralytics==8.0.106) (6.1.1)\n",
      "Collecting requests>=2.23.0\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting scipy>=1.4.1\n",
      "  Using cached scipy-1.14.1-cp310-cp310-win_amd64.whl (44.8 MB)\n",
      "Collecting pandas>=1.1.4\n",
      "  Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "Collecting torch>=1.7.0\n",
      "  Using cached torch-2.5.1-cp310-cp310-win_amd64.whl (203.1 MB)\n",
      "Collecting tqdm>=4.64.0\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting seaborn>=0.11.0\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "     ------------------------------------- 294.9/294.9 kB 33.6 kB/s eta 0:00:00\n",
      "Collecting Pillow>=7.1.2\n",
      "  Using cached pillow-11.0.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Collecting PyYAML>=5.3.1\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Collecting sentry-sdk\n",
      "  Downloading sentry_sdk-2.19.2-py2.py3-none-any.whl (322 kB)\n",
      "     ------------------------------------- 322.9/322.9 kB 21.5 kB/s eta 0:00:00\n",
      "Collecting matplotlib>=3.2.2\n",
      "  Using cached matplotlib-3.10.0-cp310-cp310-win_amd64.whl (8.0 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics==8.0.106) (24.2)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "     --------------------------------------- 71.9/71.9 kB 22.8 kB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.55.3-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics==8.0.106) (2.9.0.post0)\n",
      "Collecting numpy>=1.23\n",
      "  Using cached numpy-2.2.1-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-win_amd64.whl (218 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
      "     ------------------------------------- 102.8/102.8 kB 30.1 kB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from torch>=1.7.0->ultralytics==8.0.106) (4.12.2)\n",
      "Collecting sympy==1.13.1\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: colorama in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from tqdm>=4.64.0->ultralytics==8.0.106) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics==8.0.106) (1.17.0)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Installing collected packages: pytz, mpmath, urllib3, tzdata, tqdm, sympy, PyYAML, pyparsing, Pillow, numpy, networkx, MarkupSafe, kiwisolver, idna, fsspec, fonttools, filelock, cycler, charset-normalizer, certifi, sentry-sdk, scipy, requests, pandas, opencv-python, jinja2, contourpy, torch, matplotlib, torchvision, seaborn, ultralytics\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.0.0 PyYAML-6.0.2 certifi-2024.12.14 charset-normalizer-3.4.1 contourpy-1.3.1 cycler-0.12.1 filelock-3.16.1 fonttools-4.55.3 fsspec-2024.12.0 idna-3.10 jinja2-3.1.5 kiwisolver-1.4.8 matplotlib-3.10.0 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.1 opencv-python-4.10.0.84 pandas-2.2.3 pyparsing-3.2.0 pytz-2024.2 requests-2.32.3 scipy-1.14.1 seaborn-0.13.2 sentry-sdk-2.19.2 sympy-1.13.1 torch-2.5.1 torchvision-0.20.1 tqdm-4.67.1 tzdata-2024.2 ultralytics-8.0.106 urllib3-2.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics==8.0.106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8feffd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: filelock in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: fsspec in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ea3ead0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  Ultralytics settings reset to defaults. This is normal and may be due to a recent ultralytics package update, but may have overwritten previous settings. \n",
      "View and update settings with 'yolo settings' or at 'C:\\Users\\PMLS\\AppData\\Roaming\\Ultralytics\\settings.yaml'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'8.0.106'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6801a5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9627ba4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\MainDrive\\Work\\Projects\\TrafficMonitoringSystem\\Tracking-and-counting-Using-YOLOv8-and-DeepSORT\\env\\lib\\site-packages\\torch\\cuda\\__init__.py:493\u001b[0m, in \u001b[0;36mget_device_name\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    482\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\MainDrive\\Work\\Projects\\TrafficMonitoringSystem\\Tracking-and-counting-Using-YOLOv8-and-DeepSORT\\env\\lib\\site-packages\\torch\\cuda\\__init__.py:523\u001b[0m, in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[0;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[0;32m    524\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[1;32mc:\\MainDrive\\Work\\Projects\\TrafficMonitoringSystem\\Tracking-and-counting-Using-YOLOv8-and-DeepSORT\\env\\lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30beac26",
   "metadata": {},
   "source": [
    "# Detect, track and count Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23349aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'yolov8_DeepSORT'\n",
      "c:\\MainDrive\\Work\\Projects\\TrafficMonitoringSystem\\Tracking-and-counting-Using-YOLOv8-and-DeepSORT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MainDrive\\Work\\Projects\\TrafficMonitoringSystem\\Tracking-and-counting-Using-YOLOv8-and-DeepSORT\\env\\lib\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%cd yolov8_DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac57944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "import colorsys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0867cc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\MainDrive\\Work\\Projects\\TrafficMonitoringSystem\\Tracking-and-counting-Using-YOLOv8-and-DeepSORT\\image.png: 640x640 1 truck, 1228.9ms\n",
      "Speed: 8.5ms preprocess, 1228.9ms inference, 57.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mc:\\MainDrive\\Work\\Projects\\TrafficMonitoringSystem\\Tracking-and-counting-Using-YOLOv8-and-DeepSORT\\runs\\detect\\predict5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.0]\n",
      "Class: boat\n"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"best.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "results = model(\"image.png\", save=True)\n",
    "\n",
    "class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bbox outputs\n",
    "    probs = result.probs  # Class probabilities for classification outputs\n",
    "    cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "    xyxy = boxes.xyxy\n",
    "    xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
    "    conf = boxes.conf\n",
    "    print(cls)\n",
    "    for class_index in cls:\n",
    "        class_name = class_names[int(class_index)]\n",
    "        print(\"Class:\", class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c7b6e",
   "metadata": {},
   "source": [
    "# DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "945f584b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\MainDrive\\Work\\Projects\\TrafficMonitoringSystem\\Tracking-and-counting-Using-YOLOv8-and-DeepSORT\\deep_sort\\deep\\feature_extractor.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=torch.device(self.device))[\n"
     ]
    }
   ],
   "source": [
    "from deep_sort_pytorch.utils.parser import get_config\n",
    "from deep_sort_pytorch.deep_sort import DeepSort\n",
    "from deep_sort_pytorch.utils.tools import Tracker\n",
    "\n",
    "deep_sort_weights = 'deep_sort/deep/checkpoint/ckpt.t7'\n",
    "tracker = DeepSort(model_path=deep_sort_weights, max_age=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d74f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the video path\n",
    "video_path = '2252223-sd_640_360_30fps.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_path = 'output.mp4'\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09056afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "unique_track_ids = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "533ff5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 17 cars, 3 buss, 152.9ms\n",
      "Speed: 4.1ms preprocess, 152.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 18 cars, 2 buss, 170.2ms\n",
      "Speed: 3.0ms preprocess, 170.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 18 cars, 2 buss, 275.0ms\n",
      "Speed: 2.7ms preprocess, 275.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 18 cars, 2 buss, 167.7ms\n",
      "Speed: 3.0ms preprocess, 167.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 15 cars, 3 buss, 161.4ms\n",
      "Speed: 5.8ms preprocess, 161.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 16 cars, 2 buss, 128.9ms\n",
      "Speed: 3.5ms preprocess, 128.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 17 cars, 2 buss, 169.0ms\n",
      "Speed: 3.0ms preprocess, 169.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 18 cars, 3 buss, 170.4ms\n",
      "Speed: 3.0ms preprocess, 170.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 19 cars, 3 buss, 173.8ms\n",
      "Speed: 2.6ms preprocess, 173.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 18 cars, 2 buss, 145.8ms\n",
      "Speed: 3.0ms preprocess, 145.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 17 cars, 2 buss, 126.7ms\n",
      "Speed: 2.4ms preprocess, 126.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 17 cars, 2 buss, 175.8ms\n",
      "Speed: 3.0ms preprocess, 175.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 18 cars, 2 buss, 117.8ms\n",
      "Speed: 1.9ms preprocess, 117.8ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 18 cars, 3 buss, 157.9ms\n",
      "Speed: 3.0ms preprocess, 157.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 16 cars, 2 buss, 150.4ms\n",
      "Speed: 4.1ms preprocess, 150.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 17 cars, 2 buss, 126.7ms\n",
      "Speed: 3.5ms preprocess, 126.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 17 cars, 2 buss, 114.0ms\n",
      "Speed: 2.0ms preprocess, 114.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 15 cars, 3 buss, 123.8ms\n",
      "Speed: 1.0ms preprocess, 123.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 114.4ms\n",
      "Speed: 1.0ms preprocess, 114.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 bus, 112.2ms\n",
      "Speed: 2.0ms preprocess, 112.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 bus, 114.3ms\n",
      "Speed: 2.0ms preprocess, 114.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 bus, 193.6ms\n",
      "Speed: 2.0ms preprocess, 193.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 bus, 116.1ms\n",
      "Speed: 2.5ms preprocess, 116.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 buss, 1 truck, 141.3ms\n",
      "Speed: 2.0ms preprocess, 141.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 2 buss, 122.1ms\n",
      "Speed: 3.3ms preprocess, 122.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 buss, 152.9ms\n",
      "Speed: 2.0ms preprocess, 152.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 bus, 108.9ms\n",
      "Speed: 2.7ms preprocess, 108.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 buss, 178.8ms\n",
      "Speed: 2.9ms preprocess, 178.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 bus, 112.8ms\n",
      "Speed: 2.0ms preprocess, 112.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 bus, 127.6ms\n",
      "Speed: 3.0ms preprocess, 127.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 buss, 118.6ms\n",
      "Speed: 2.5ms preprocess, 118.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 115.7ms\n",
      "Speed: 2.5ms preprocess, 115.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 bus, 121.2ms\n",
      "Speed: 2.0ms preprocess, 121.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 buss, 131.6ms\n",
      "Speed: 2.0ms preprocess, 131.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 114.7ms\n",
      "Speed: 3.5ms preprocess, 114.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 bus, 172.4ms\n",
      "Speed: 3.0ms preprocess, 172.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 bus, 138.7ms\n",
      "Speed: 3.0ms preprocess, 138.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 3 buss, 126.4ms\n",
      "Speed: 3.0ms preprocess, 126.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 buss, 145.2ms\n",
      "Speed: 2.9ms preprocess, 145.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 buss, 181.8ms\n",
      "Speed: 3.0ms preprocess, 181.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 buss, 128.1ms\n",
      "Speed: 2.0ms preprocess, 128.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 buss, 113.2ms\n",
      "Speed: 2.5ms preprocess, 113.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 buss, 112.7ms\n",
      "Speed: 2.0ms preprocess, 112.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 buss, 134.1ms\n",
      "Speed: 3.0ms preprocess, 134.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 buss, 119.7ms\n",
      "Speed: 2.0ms preprocess, 119.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 buss, 114.0ms\n",
      "Speed: 2.0ms preprocess, 114.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 bus, 113.4ms\n",
      "Speed: 2.0ms preprocess, 113.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 buss, 122.3ms\n",
      "Speed: 2.0ms preprocess, 122.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 140.5ms\n",
      "Speed: 2.0ms preprocess, 140.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 buss, 167.9ms\n",
      "Speed: 3.0ms preprocess, 167.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 bus, 198.3ms\n",
      "Speed: 4.0ms preprocess, 198.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 bus, 120.6ms\n",
      "Speed: 2.1ms preprocess, 120.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 bus, 124.6ms\n",
      "Speed: 0.9ms preprocess, 124.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 bus, 116.6ms\n",
      "Speed: 1.5ms preprocess, 116.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 133.2ms\n",
      "Speed: 2.9ms preprocess, 133.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 139.9ms\n",
      "Speed: 3.0ms preprocess, 139.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 112.7ms\n",
      "Speed: 3.4ms preprocess, 112.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 bus, 127.0ms\n",
      "Speed: 4.7ms preprocess, 127.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 10 cars, 2 buss, 119.7ms\n",
      "Speed: 3.0ms preprocess, 119.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 13 cars, 2 buss, 122.6ms\n",
      "Speed: 2.0ms preprocess, 122.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 buss, 112.5ms\n",
      "Speed: 3.0ms preprocess, 112.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "counter, fps, elapsed = 0, 0, 0\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        \n",
    "        og_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = og_frame.copy()\n",
    "\n",
    "        model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "        results = model(frame)\n",
    "\n",
    "        class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "         'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes  # Boxes object for bbox outputs\n",
    "            probs = result.probs  # Class probabilities for classification outputs\n",
    "            cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "            xyxy = boxes.xyxy\n",
    "            conf = boxes.conf\n",
    "            xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
    "            for class_index in cls:\n",
    "                class_name = class_names[int(class_index)]\n",
    "                #print(\"Class:\", class_name)\n",
    "\n",
    "        pred_cls = np.array(cls)\n",
    "        conf = conf.detach().cpu().numpy()\n",
    "        xyxy = xyxy.detach().cpu().numpy()\n",
    "        bboxes_xywh = xywh\n",
    "        bboxes_xywh = xywh.cpu().numpy()\n",
    "        bboxes_xywh = np.array(bboxes_xywh, dtype=float)\n",
    "        \n",
    "        tracks = tracker.update(bboxes_xywh, conf, og_frame)\n",
    "        \n",
    "        for track in tracker.tracker.tracks:\n",
    "            track_id = track.track_id\n",
    "            hits = track.hits\n",
    "            x1, y1, x2, y2 = track.to_tlbr()  # Get bounding box coordinates in (x1, y1, x2, y2) format\n",
    "            w = x2 - x1  # Calculate width\n",
    "            h = y2 - y1  # Calculate height\n",
    "\n",
    "            # Set color values for red, blue, and green\n",
    "            red_color = (0, 0, 255)  # (B, G, R)\n",
    "            blue_color = (255, 0, 0)  # (B, G, R)\n",
    "            green_color = (0, 255, 0)  # (B, G, R)\n",
    "\n",
    "            # Determine color based on track_id\n",
    "            color_id = track_id % 3\n",
    "            if color_id == 0:\n",
    "                color = red_color\n",
    "            elif color_id == 1:\n",
    "                color = blue_color\n",
    "            else:\n",
    "                color = green_color\n",
    "\n",
    "            cv2.rectangle(og_frame, (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, 2)\n",
    "\n",
    "            text_color = (0, 0, 0)  # Black color for text\n",
    "            cv2.putText(og_frame, f\"{class_name}-{track_id}\", (int(x1) + 10, int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "            # Add the track_id to the set of unique track IDs\n",
    "            unique_track_ids.add(track_id)\n",
    "\n",
    "        # Update the person count based on the number of unique track IDs\n",
    "        person_count = len(unique_track_ids)\n",
    "\n",
    "        # Update FPS and place on frame\n",
    "        current_time = time.perf_counter()\n",
    "        elapsed = (current_time - start_time)\n",
    "        counter += 1\n",
    "        if elapsed > 1:\n",
    "            fps = counter / elapsed\n",
    "            counter = 0\n",
    "            start_time = current_time\n",
    "\n",
    "        # Draw person count on frame\n",
    "        cv2.putText(og_frame, f\"Car Count: {person_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Append the frame to the list\n",
    "        frames.append(og_frame)\n",
    "\n",
    "        # Write the frame to the output video file\n",
    "        out.write(cv2.cvtColor(og_frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow(\"Video\", og_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2fc33ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\MainDrive\\Work\\Projects\\TrafficMonitoringSystem\\Tracking-and-counting-Using-YOLOv8-and-DeepSORT\\predict.py\", line 3, in <module>\n",
      "    import hydra\n",
      "ModuleNotFoundError: No module named 'hydra'\n"
     ]
    }
   ],
   "source": [
    "!python predict.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53e8c438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hydra\n",
      "  Using cached Hydra-2.5.tar.gz (82 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Using legacy 'setup.py install' for hydra, since package 'wheel' is not installed.\n",
      "Installing collected packages: hydra\n",
      "  Running setup.py install for hydra: started\n",
      "  Running setup.py install for hydra: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Running setup.py install for hydra did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [11 lines of output]\n",
      "      running install\n",
      "      C:\\MainDrive\\Work\\Projects\\TrafficMonitoringSystem\\Tracking-and-counting-Using-YOLOv8-and-DeepSORT\\env\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "        warnings.warn(\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-cpython-310\n",
      "      copying src\\hydra.py -> build\\lib.win-amd64-cpython-310\n",
      "      running build_ext\n",
      "      building '_hydra' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "× Encountered error while trying to install package.\n",
      "╰─> hydra\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f620bee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: tqdm in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from gdown) (2.32.3)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from requests[socks]->gdown) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from requests[socks]->gdown) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from requests[socks]->gdown) (2024.12.14)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: colorama in c:\\maindrive\\work\\projects\\trafficmonitoringsystem\\tracking-and-counting-using-yolov8-and-deepsort\\env\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Installing collected packages: soupsieve, PySocks, beautifulsoup4, gdown\n",
      "Successfully installed PySocks-1.7.1 beautifulsoup4-4.12.3 gdown-5.2.0 soupsieve-2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1UUZUS76ylH5RjMSc9s4rITSYDTG5AHt0&confirm=t\n",
      "To: c:\\MainDrive\\Work\\Projects\\TrafficMonitoringSystem\\Tracking-and-counting-Using-YOLOv8-and-DeepSORT\\test4.mp4\n",
      "\n",
      "  0%|          | 0.00/7.96M [00:00<?, ?B/s]\n",
      "  7%|▋         | 524k/7.96M [00:00<00:07, 1.05MB/s]\n",
      " 13%|█▎        | 1.05M/7.96M [00:00<00:04, 1.62MB/s]\n",
      " 20%|█▉        | 1.57M/7.96M [00:00<00:03, 2.00MB/s]\n",
      " 26%|██▋       | 2.10M/7.96M [00:01<00:02, 2.07MB/s]\n",
      " 33%|███▎      | 2.62M/7.96M [00:01<00:02, 1.86MB/s]\n",
      " 39%|███▉      | 3.15M/7.96M [00:01<00:02, 1.86MB/s]\n",
      " 46%|████▌     | 3.67M/7.96M [00:01<00:02, 2.00MB/s]\n",
      " 53%|█████▎    | 4.19M/7.96M [00:02<00:01, 1.95MB/s]\n",
      " 59%|█████▉    | 4.72M/7.96M [00:02<00:01, 2.13MB/s]\n",
      " 66%|██████▌   | 5.24M/7.96M [00:02<00:01, 2.15MB/s]\n",
      " 72%|███████▏  | 5.77M/7.96M [00:02<00:01, 2.04MB/s]\n",
      " 79%|███████▉  | 6.29M/7.96M [00:03<00:00, 1.91MB/s]\n",
      " 86%|████████▌ | 6.82M/7.96M [00:03<00:00, 1.77MB/s]\n",
      " 92%|█████████▏| 7.34M/7.96M [00:03<00:00, 1.80MB/s]\n",
      " 99%|█████████▊| 7.86M/7.96M [00:04<00:00, 2.05MB/s]\n",
      "100%|██████████| 7.96M/7.96M [00:04<00:00, 1.93MB/s]\n"
     ]
    }
   ],
   "source": [
    "%pip install gdown\n",
    "\n",
    "!gdown \"https://drive.google.com/uc?id=1UUZUS76ylH5RjMSc9s4rITSYDTG5AHt0&confirm=t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5228cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
